## *****************************************************************************
##
## Licensed to the Apache Software Foundation (ASF) under one
## or more contributor license agreements.  See the NOTICE file
## distributed with this work for additional information
## regarding copyright ownership.  The ASF licenses this file
## to you under the Apache License, Version 2.0 (the
## "License"); you may not use this file except in compliance
## with the License.  You may obtain a copy of the License at
##
##   http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing,
## software distributed under the License is distributed on an
## "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
## KIND, either express or implied.  See the License for the
## specific language governing permissions and limitations
## under the License.
##
## ******************************************************************************

#---- List of all DataLab parameters (commented ones are passing from UI/Jenkins) ----#


#--- [conf] section contains all common for all templates parameters ---#
[conf]
### Unique infrastructure name
# service_base_name =
### DataLab ssh user name ('datalab-user' by default)
os_user = datalab-user
### OS that supported by DataLab (debian/redhat)
# os_family =
### Cloud provider that supported by DataLab (aws/azure)
# cloud_provider =
### Admin ssh key name in cloud provider
# key_name =
### Directory in Docker where key is uploaded
key_dir = /root/keys/
### Type of the provisionong stage (should be change for 'prod')
lifecycle_stage = dev
### The name of user for tag, which will be set for all resources
# tag_resource_id = user:tag
### Pypi mirror for China
pypi_mirror = pypi.doubanio.com
### Name of own GitLab SSL certificate
gitlab_certfile = datalab-gitlab.crt
### Enable or Disable creating image at first time
image_enabled = true
###Enable or Disable shared images
#shared_image_enabled = true
### CIDR of VPC
vpc_cidr = '172.31.0.0/16'
### CIDR of second VPC
vpc2_cidr = '172.32.0.0/16'
### Enable or disable duo VPC mode(true|false)
duo_vpc_enable = false
### Range of subnets which will be used for user's environments
# user_subnets_range = 172.31.0.0/24 - 172.31.50.0/24
### Comma-separated CIDR of IPs which will have access to SSN and Edge nodes
allowed_ip_cidr = '0.0.0.0/0'
### Type of network. Define in which network DataLab will be deployed. Possible options: public|private
network_type = public
### Additional tags in format 'Key1:Value1;Key2:Value2'
# additional_tags =
pip_version = 21.0.1
### Billing tag key
billing_tag_key = product
### Billing tag value
billing_tag_value = datalab
### Enable or disable Step certificates
stepcerts_enabled = false
### Step root certificate in base64 format
# stepcerts_root_ca =
### Step certificates kid
# stepcerts_kid =
### Step certificates kid password
# stepcerts_kid_password =
### Step certificates CA URL
# stepcerts_ca_url =
### Enable or disable Lets Encrypt certificates
letsencrypt_enabled = false
### Domain names to apply
# letsencrypt_domain_name =
### email address to use
# letsencrypt_email =
### Prefix of the private subnet
private_subnet_prefix = 24

#--- [aws] section contains all common parameters related to Amazon ---#
[aws]
### Amazon iam user access_key
# access_key =
### Amazon iam user secret_access_key
# secret_access_key =
### Id of the security group for SSN instance
# security_groups_ids =
### Id of the subnet for SSN and EDGE provisioning
# subnet_id =
### Id of the subnet for notebooks and compute engines
# subnet2_id =
### Id of the vpc for whole DataLab provisioning
# vpc_id =
### Id of the secondary vpc for notebooks and compute engines
# vpc2_id =
### Amazon peering connection id
# peering_id =
### Amazon iam user name
# iam_user =
### EC2 instance type for notebook
# notebook_instance_type =
### EC2 instance type for SSN
ssn_instance_size = t2.large
### EC2 instance type for EDGE
edge_instance_size = t2.medium
### Amazon region name for whole DataLab provisioning
region = us-west-2
### Amazon zone letter for ssn, edge and notebook subnet provisioning
# zone =
### Amazon ami name based on debian conf_os_family for all DataLab instances
debian_image_name = ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20201026
### Amazon ami name based on RedHat conf_os_family for all DataLab instances
redhat_image_name = RHEL-7.4_HVM-20180103-x86_64-2-Hourly2-GP2
### Amazon account ID
# account_id =
### Amazon billing bucket
# billing_bucket =
### Path to billing reports in S3 bucket
# report_path =
### Predefined policies for users instances
# user_predefined_s3_policies =


#--- [azure] section contains all common parameters related to Azure ---#
[azure]
### Region
# region =
### Resource Group name
# resource_group_name =
### VPC name
# vpc_name =
### Subnet name
# subnet_name =
### name Will create exploratory environment with edge node as access point as followingof the security group for edge instance
# edge_security_group_name =
### EC2 instance type for SSN
ssn_instance_size = Standard_DS2_v2
### Instance type for EDGE
edge_instance_size = Standard_DS1_v2
### Master node size for Data Engine
# dataengine_master_size =
### Slave node size for Data Engine
# dataengine_slave_size =
### Azure image name based on debian conf_os_family for all DataLab instances
debian_image_name = Canonical_UbuntuServer_20.04-LTS
### Azure image name based on RedHat conf_os_family for all DataLab instances
redhat_image_name = RedHat_RHEL_7.3
### Azure AD user name
# user_name =
### Azure AD user refresh token
# user_refresh_token =
### Full path to Azure credentials JSON file
#auth_path =
### Azure offer number
# offer_number =
### Azure billin currency code
# currency =
### Azure language locale
locale = en-US
### Azure region code
# region_info =
### Azure datalake to create
datalake_enable = false
### Azure login application ID
# application_id =

[gcp]
### GCP project ID
# project_id =
### Full path to service account JSON
# service_account_path =
### Name of the vpc for whole DataLab provisioning
# vpc_name =
### Name of the subnet for SSN and EDGE provisioning
# subnet_name =
### Names of the firewall rules for SSN
# firewall_rules =
### GCP region name for whole DataLab provisioning
region = us-west1
### GCP zone name for whole DataLab provisioning
zone = us-west1-a
### GCP ami name based on debian conf_os_family for all DataLab instances
debian_image_name = /projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20210119a
### GCP ami name based on RedHat conf_os_family for all DataLab instances
redhat_image_name =
### Prefix of the private subnet
### Instance type for EDGE
ssn_instance_size = n1-standard-2
### Instance type for EDGE
edge_instance_size = n1-standard-1
### GPU type for Tensor/DeepLaerning notebooks
gpu_accelerator_type = nvidia-tesla-k80

#--- [ssn] section contains all parameters that are using for self-service node provisioning ---#
[ssn]
### System path on SSN instance where DataLab will be installed
datalab_path = /opt/datalab/
### Elastic IP which will be associated with SSN node
# elastic_ip =
### Version of Docker to be installed on SSN
docker_version = 20.10.2
### Name of hosted zone for Route53
# hosted_zone_name =
### ID of hosted zone
# hosted_zone_id =
### Subdomain name
# subdomain =
### Role ARN for creating Route53 record
# assume_role_arn =

#--- [edge] section contains all parameters that are using for edge node provisioning ---#
[edge]
### User name for exploratory environment being deployed
# user_name =
### Elastic IP which will be associated with Edge node
# elastic_ip =
### Edge node is NAT
is_nat = true

#--- [notebook] section contains all parameters that are using for all notebooks provisioning ---#
[notebook]
### Notebook EC2 instance name
# instance_name =
### Size of the additional volume for notebook instance
disk_size = 30
### Version of Apache Spark to be installed on notebook
spark_version = 2.4.4
### Version of Apache Hadoop to be installed on notebook
hadoop_version = 2.7
### Version of Jupyter to be installed on notebook
jupyter_version = 6.1.6
### Version of TensorFlow to be installed on notebook
tensorflow_version = 2.3.2
### Version of Zeppelin to be installed on notebook
zeppelin_version = 0.9.0
### Version of Rstudio to be installed on notebook
rstudio_version = 1.4.1103
### Version of Scala to be installed on notebook
scala_version = 2.12.8
### Version of Livy top be installed on notebook
livy_version = 0.3.0
### If it is true, Livy will be used on Zeppelin notebook
multiple_clusters = false
### R China mirror
r_mirror = http://mirror.lzu.edu.cn/CRAN/
### NVidia driver version for Tensor/DeepLearning notebooks
nvidia_version = 418.126.02
### Caffe library version for DeepLearning notebook
caffe_version = 1.0
### Caffe2 library version for DeepLearning notebook
caffe2_version = 1.5
### Pytorch branch used during caffe2 installation for DeepLearning notebook
pytorch_branch = release/1.5
### Cmake version for DeepLearning notebook
cmake_version = 3.15.5
### CNTK library version for DeepLearning notebook for python3
cntk_version = 2.7
### MXNet library version for DeepLearning notebook for python
mxnet_version = 1.6.0.post0
### Keras library version for Tensor/DeepLearning notebook
keras_version = 2.1.6
### Theano library version for Tensor/DeepLearning notebook
theano_version = 1.0.3
### Version of CUDA
cuda_version = 10.1
### Name of CUDA file
cuda_file_name = cuda_10.1.243_418.87.00_linux.run
### Version of CUDNN
cudnn_version = 7.6.5
### Name of CUDNN file
cudnn_file_name = cudnn-10.1-linux-x64-v7.6.5.32.tgz
### R enabled on Jupyter/Zeppelin notebook
r_enabled = true
### Temporary fixed python libraries due to dependencies
tornado_version = 5.1.1
ipykernel_version = 4.8.2
### Version of ungit if previous needed. Use latest as default.
ungit_version = 1.5.15
### Numpy version
numpy_version = 1.18.3
### caTools version for R 3.4.4
catools_version = 1.17.1.4
### Apache Ivy version
ivy_version = 2.4.0
### Matplotlib version
matplotlib_version = 2.0.2
### JupyterLab image
jupyterlab_image = odahu\\/base-notebook:1.1.0-rc8
### Superset version
superset_version = 0.35.1
### GCS-connector version
gcs_connector_version = 2.0.1
### Setuptools version
setuptools_version = 41.0.0

#--- [emr] section contains all parameters that are using for emr provisioning ---#
[emr]
### EMR cluster namr
# cluster_name =
### Period of time while EMR being provisioned (default is 1500)
# timeout =
### Amount of ENR nodes
# instance_count =
### EC2 instance type for master node
# master_instance_type =
### EC2 instance type for all slaves nodes
# slave_instance_type =
### EMR version
# version =
### EMR instance role name
ec2_role = EMR_EC2_DefaultRole
### EMR role name
service_role = EMR_DefaultRole
###
excluded_spark_properties = '"spark.master", "spark.eventLog.enabled", "spark.eventLog.dir", "spark.history.fs.logDirectory", "spark.sql.warehouse.dir", "spark.driver.memory", "spark.executor.extraLibraryPath", "spark.executor.extraClassPath"'
### Enable/Disable EC2 Spot instances for EMR slaves
slave_instance_spot = True
### Percentage of the EC2 price
slave_instance_spot_pct_price = 70

#--- [dataengine] section contains all parameters that are using for dataengine provisioning ---#
[dataengine]
### Count of slave nodes for Data Engine
# instance_count =
### Type of notebooks for creating Data Engine from notebook images
image_notebooks = jupyter,jupyterlab,rstudio,zeppelin,tensor,tensor-rstudio,deeplearning
### Persent of RAM allocated for an operating system
os_memory = 75
### Explicit allocation RAM for an operating system
os_expl_memory = 3500
### Depending on RAM size on instance, this parameter determines size of RAM when explicit allocation RAM is used
expl_instance_memory = 8000

#--- [ldap] ldap parameters ---#
[ldap]
### Ldap hostname
# hostname =
### Ldap architecture params
# dn =
### Ldap organisation unit
# ou =
### Ldap admin password
# service_password =
### Ldap admin user name
# service_username =

#--- [keycloak] keycloak parameters ---#
[keycloak]
### Keycloak realm name
# realm_name =
### Keycloak auth server url
# auth_server_url =
### Keycloak client name
# client_name =
### Keycloak client secret
# client_secret =
### Keycloak user
# user =
### Keycloak user password
# user_password =

#--- [reverse_proxy] reverse proxy settings ---#
[reverse_proxy]
### Nginx version
nginx_version = 1.15.1